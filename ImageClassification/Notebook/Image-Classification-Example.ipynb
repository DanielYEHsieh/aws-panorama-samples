{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create a Lambda Function for Image Classifcation in AWS Panorama "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this notebook accomplishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to create and deploy a lambda function that is used for a semantic segmentation application using the AWS Panorama service. \n",
    "- You will learn the parts of an Panorama application and what they are used for. \n",
    "- Then you will put it all together to simulate an image classification application within the environment of this notebook. \n",
    "\n",
    "\n",
    "The application uses a pretrained image classification model from GluonCV/MXNET. You can find more information and tutorials for image classification using [MXNET & GluonCV](https://gluon-cv.mxnet.io/build/examples_classification/index.html) tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frames to Process**:\n",
    "\n",
    "* By default, we only process 10 frames from the video. If you want to increase this, please change this value in /panorama_sdk/panoramasdk.py and change frames_to_process = 10 to a value of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change video to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_use = \"mountain.mp4\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Image Classification\n",
    "\n",
    "- Image Classification is one of few foundational computer vision tasks that provide the basis for performing other more difficult tasks. \n",
    "- Object detection is an example of a CV Task that uses a pretrained base trained using an image classification dataset. \n",
    "- With image classification, we are simply trying to classify what the image is, i.e *a cat or dog*\n",
    "- An application of this is a farmer trying to classify tomatoes as good or bad as part of their sorting process. \n",
    "- Another could be a wood sourcer that needs to determine which cuts of wood can be used and which ones cannot. \n",
    "\n",
    "#### 1.1 The end to end process for Image Classification inference is relatively simple. \n",
    "- It consists of taking an image (or in this case a video frame) and preprocessing it\n",
    "- performing model inference\n",
    "- post-processing model's output to determine what class the image belongs to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Run the next cell to define the preprocessing functions. \n",
    "These functions are responsible for performing transformations and normalizing so that inference performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def preprocess(\n",
    "    img,\n",
    "    resize_short=256,\n",
    "    crop_size=224,\n",
    "    mean=(0.485, 0.456, 0.406),\n",
    "    std=(0.229, 0.224, 0.225),\n",
    "):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # resize to resize short\n",
    "    # find the short size,\n",
    "    width = img.shape[0]\n",
    "    height = img.shape[1]\n",
    "\n",
    "    height_is_short = int(width > height)  #\n",
    "\n",
    "    if height_is_short:\n",
    "        width = int(width * (resize_short / height))\n",
    "        height = resize_short\n",
    "    else:\n",
    "        height = int(height * (resize_short / width))\n",
    "        width = resize_short\n",
    "\n",
    "    img = cv2.resize(img, (height, width))\n",
    "\n",
    "    # center crop\n",
    "    xmin = int(width / 2 - crop_size / 2)\n",
    "    xmax = int(width / 2 + crop_size / 2)\n",
    "    ymin = int(height / 2 - crop_size / 2)\n",
    "    ymax = int(height / 2 + crop_size / 2)\n",
    "\n",
    "    img = img[xmin:xmax, ymin:ymax, :]\n",
    "    # normalize\n",
    "\n",
    "    img = normalize(img, mean=mean, std=std)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "\n",
    "    img = img.astype(np.float32) / 255.0  # converting array of ints to floats\n",
    "    img_a = img[:, :, 0]\n",
    "    img_b = img[:, :, 1]\n",
    "    img_c = img[:, :, 2]\n",
    "\n",
    "    # Extracting single channels from 3 channel image\n",
    "    # The above code could also be replaced with cv2.split(img) << which will return 3 numpy arrays (using opencv)\n",
    "\n",
    "    # normalizing per channel data:\n",
    "    img_a = (img_a - mean[0]) / std[0]\n",
    "    img_b = (img_b - mean[1]) / std[1]\n",
    "    img_c = (img_c - mean[2]) / std[2]\n",
    "\n",
    "    # putting the 3 channels back together:\n",
    "    x1 = [[[], [], []]]\n",
    "    x1[0][0] = img_a\n",
    "    x1[0][1] = img_b\n",
    "    x1[0][2] = img_c\n",
    "\n",
    "    # x1 = mx.nd.array(np.asarray(x1))\n",
    "    x1 = np.asarray(x1)\n",
    "\n",
    "    return x1\n",
    "\n",
    "\n",
    "def softmax(logits):\n",
    "    ps = np.exp(logits)\n",
    "    ps /= np.sum(ps)\n",
    "\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Next, read in the image and transform it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mt_baker.jpg\"\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "# x is in the input that goes directly into the model\n",
    "x = preprocess(img)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Define a utility function for getting the indices of the top K probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk(array, k=5):\n",
    "    enum_vals = [(i, val) for i, val in enumerate(array)]\n",
    "    sorted_vals = sorted(enum_vals, key=lambda tup: tup[1])\n",
    "    top_k = sorted_vals[::-1][:k]\n",
    "    return [tup[0] for tup in top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Load the model and perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagenet_classes import get_classes\n",
    "from gluoncv import model_zoo\n",
    "import mxnet as mx\n",
    "\n",
    "model = model_zoo.get_model(\"resnet50_v2\", pretrained=True)\n",
    "classes = get_classes()\n",
    "logits = model(mx.nd.array(x))\n",
    "probs = softmax(logits[0].asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Process model output and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 5\n",
    "ind = topk(probs, k=topK)\n",
    "\n",
    "top = \"The input picture is classified to be:\"\n",
    "image = cv2.putText(\n",
    "    img, top, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 5\n",
    ")\n",
    "for j in range(topK):\n",
    "    line = \"class [%s], with probability %.3f.\" % (\n",
    "        classes[ind[j]],\n",
    "        probs[ind[j]],\n",
    "    )\n",
    "    coords = (50, 100 + (j + 1) * 100)\n",
    "    image = cv2.putText(\n",
    "        image, line, coords, cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 5\n",
    "    )\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to building the Panorama application code that will be part of the lambda is understanding what parts of the **Panorama Application Class** are necessary. This class is what is used by the Panorama service to manage the model, preprocessing and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At a high level, the raw code cell below is what the application class looks like. \n",
    "- The `interface`, `init`, and `entry` methods are the basic necessary components to building the application class.\n",
    "\n",
    "**Note**: In addition to these methods, you can add custom methods either to the class or the script globally. You will see both illustrated in the final lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class image_classifier(panoramasdk.base):\n",
    "    def interface(self):\n",
    "        # defines the parameters that interface with other services from Panorama\n",
    "        \n",
    "    def init(self, parameters, inputs, outputs):\n",
    "        # defines the attributes such as arrays and model objects that will be used in the application\n",
    "        \n",
    "    def entry(self, inputs, outputs):\n",
    "        # defines the application logic responsible for predicting using the inputs and handles what to do \n",
    "        # with the outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining the `interface` method\n",
    "The first method to define is the `interface` method. This is an important part of the Panorama application because this is how the application interacts with the resources from the Panorama service. When creating an Panorama Application in the Panorama console, you should have specified the model that will be used for predicting, the IP camera input streams and where the application's output is going. \n",
    "- The Panorama Service compiles your pretrained model and prepares it to be deployed to the Manhattan device. \n",
    "- Camera inputs are defined so that each camera's stream images are passed to the application to be predicted on by the AWS Lambda function's application code.\n",
    "- Outputs are defined to receive the model's post-processed output. This is usually set to output to HDMI for visualizing results.\n",
    "\n",
    "Lastly, the interface method then defines these inputs and outputs within the Panorama application class so that the application has access to them in the `entry` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def interface(self):\n",
    "    return {\n",
    "        \"parameters\":\n",
    "            (\n",
    "                (\"model\", \"classifier\", \"Model for classifying images\", \"classification-model\"),\n",
    "                (\"int\", \"batch_size\", \"Model batch size\", 1),\n",
    "            ),\n",
    "        \"inputs\":\n",
    "            (\n",
    "                (\"media[]\", \"video_in\", \"Camera input stream\"),\n",
    "            ),\n",
    "        \"outputs\":\n",
    "            (\n",
    "                (\"media[video_in]\", \"video_out\", \"Camera output stream\"),\n",
    "            )\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `interface` method returns a dictionary of items that define parameters, inputs and outputs. \n",
    "- These items consist of an array of tuples. \n",
    "- Each tuple follows this schema:\n",
    "\n",
    "(`data type`, `variable name`, `description`, `value`)\n",
    "\n",
    "**Tip**: You can add your own parameters to the `parameters` object, that can be later used in the `init` method. \n",
    "\n",
    "For this example, you will set the value of the `classifier` parameter to **\"classification-model\"**, and in the future you will set it to the name of the model you have defined to be part of the Panorama application in the Panorama Console. Batch size will always be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Defining the `init` method\n",
    "\n",
    "The init method serves a similar purpose to traditional `__init__` methods used in python classes. \n",
    "- The difference here is that the initialization parameters come from the `parameters` object passed. \n",
    "- Using this `parameters` object, you can initialize the model that has been previously uploaded in the Panorama Console. \n",
    "- You will also define array containers for the model's output based on the model's output shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def init(self, parameters, inputs, outputs):\n",
    "    try:\n",
    "        self.frame_num = 0\n",
    "\n",
    "        # Load model from the specified directory.\n",
    "        print(\"loading the model...\")\n",
    "        self.model = panoramasdk.model()\n",
    "        self.model.open(parameters.classifier, 1)\n",
    "        print(\"model loaded\")\n",
    "\n",
    "        # Create input and output arrays.\n",
    "        prob_info = self.model.get_output(0)\n",
    "       \n",
    "        self.prob_array = np.empty(prob_info.get_dims(), dtype=prob_info.get_type())\n",
    "        \n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception: {}\".format(e))\n",
    "        return False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note, with the code below\n",
    "```\n",
    "...\n",
    "self.model = panoramasdk.model()\n",
    "self.model.open(parameters.classififier, 1)\n",
    "...\n",
    "```\n",
    "First, an `panoramasdk.model` object is initialized, then the pretrained model is loaded into that object. \n",
    "- It knows what model to load based on the parameter you set in `interface` for the corrresponding model parameter. \n",
    "- In this notebook you will use a different pattern so that it can be demo-ed in a notebook environment, but it will behave similarly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Defining the `entry` method\n",
    "\n",
    "The entry method is the *entry* point for the Panorama application; and it contains all the logic to perform for each video input, for each frame. This is where you will perform the preprocessing, inferencing, and post-processing. \n",
    "For the classification task, it's as simple as the following steps:\n",
    "\n",
    "1. preprocess the image input\n",
    "2. perform inference\n",
    "3. get the results\n",
    "4. filter out the top k most probable classes\n",
    "5. add text to the stream.image displaying the k most probable classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def entry(self, inputs, outputs):\n",
    "\n",
    "    for i in range(len(inputs.video_in)):\n",
    "\n",
    "        stream = inputs.video_in[i]\n",
    "\n",
    "        person_image = stream.image\n",
    "\n",
    "        print(\"Processing Image...\")\n",
    "        x1 = preprocess(person_image)\n",
    "        print(\"Processed Image\")\n",
    "\n",
    "\n",
    "        # Do inference on the new frame.\n",
    "        print(\"Performing Detector Inference\")\n",
    "        self.model.batch(0, x1)\n",
    "        self.model.flush()\n",
    "        print(\"Inference Completed.\")\n",
    "\n",
    "        # Get the results.\n",
    "        resultBatchSet = self.model.get_result()\n",
    "\n",
    "        prob_batch = resultBatchSet.get(0)\n",
    "        prob_batch.get(0, self.prob_array)\n",
    "\n",
    "        logits = self.prob_array[0]\n",
    "        topK = 5\n",
    "        ind = self.topk(pred, k=topK)\n",
    "\n",
    "        probs = softmax(logits)\n",
    "        lines = []\n",
    "        for i in range(topK):\n",
    "            lines.append('class [%s], with probability %.3f.'%\n",
    "              (classes[ind[i]], probs[ind[i]]))\n",
    "        message = \"\\n\".join(lines)\n",
    "\n",
    "        stream.add_label(message, 0.65, 0.65)\n",
    "\n",
    "\n",
    "\n",
    "    self.model.release_result(resultBatchSet)\n",
    "    outputs.video_out[i] = stream\n",
    "\n",
    "    return True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Extra Methods \n",
    "As mentioned previously, you can add helpful methods to either the application class or the script globally. \n",
    "- The raw code cell below is an example of a helpful method added to the class. \n",
    "- It is defined the same way as you would for a typical python class. \n",
    "- Examples of adding custom functions globally are shown in the **Putting it all together** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def topk(self, array, k=5):\n",
    "    enum_vals = [(i, val) for i, val in enumerate(array)]\n",
    "    sorted_vals = sorted(enum_vals, key=lambda tup: tup[1])\n",
    "    top_k = sorted_vals[::-1][:k]\n",
    "    return [tup[0] for tup in top_k]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Putting it all together\n",
    "\n",
    "A version of the lambda code compatible within a notebook environment has been written for you below. Run the next cell to visualize the application's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.abspath(os.path.join(os.path.dirname(\"panorama_sdk\"), '../..'))\n",
    "sys.path.insert(1, path + '/panorama_sdk')\n",
    "import jupyter_utils\n",
    "\n",
    "jupyter_utils.change_video_source(video_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Panorama Modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Markdown, display\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panoramasdk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "from imagenet_classes import get_classes\n",
    "\n",
    "#[AWS Panorama Documentation](https://docs.aws.amazon.com/panorama/)\n",
    "\n",
    "\n",
    "def preprocess(img, resize_short=256, crop_size=224,\n",
    "                   mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # resize to resize short\n",
    "    # find the short size, \n",
    "    width = img.shape[0]\n",
    "    height = img.shape[1]\n",
    "\n",
    "    height_is_short = int(width > height) #\n",
    "\n",
    "    if height_is_short:\n",
    "        width = int(width * (resize_short/height))\n",
    "        height = resize_short\n",
    "    else:\n",
    "        height = int(height * (resize_short/width))\n",
    "        width = resize_short\n",
    "    \n",
    "    img = cv2.resize(img, (height, width))\n",
    "    \n",
    "    # center crop\n",
    "    xmin = int(width/2 - crop_size/2)\n",
    "    xmax = int(width/2 + crop_size/2)\n",
    "    ymin = int(height/2 - crop_size/2)\n",
    "    ymax = int(height/2 + crop_size/2)\n",
    "    \n",
    "    img = img[xmin:xmax, ymin:ymax, :]\n",
    "    # normalize\n",
    "    \n",
    "    img = normalize(img, mean=mean, std=std)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "\n",
    "    img = img.astype(np.float32) / 255.  # converting array of ints to floats\n",
    "    img_a = img[:, :, 0]\n",
    "    img_b = img[:, :, 1]\n",
    "    img_c = img[:, :, 2]\n",
    "\n",
    "    # Extracting single channels from 3 channel image\n",
    "    # The above code could also be replaced with cv2.split(img) << which will return 3 numpy arrays (using opencv)\n",
    "\n",
    "    # normalizing per channel data:\n",
    "    img_a = (img_a - mean[0]) / std[0]\n",
    "    img_b = (img_b - mean[1]) / std[1]\n",
    "    img_c = (img_c - mean[2]) / std[2]\n",
    "\n",
    "    # putting the 3 channels back together:\n",
    "    x1 = [[[], [], []]]\n",
    "    x1[0][0] = img_a\n",
    "    x1[0][1] = img_b\n",
    "    x1[0][2] = img_c\n",
    "\n",
    "    # x1 = mx.nd.array(np.asarray(x1))\n",
    "    x1 = np.asarray(x1)\n",
    "    \n",
    "    return x1    \n",
    "\n",
    "def softmax(logits):\n",
    "    ps = np.exp(logits)\n",
    "    ps /= np.sum(ps)\n",
    "    \n",
    "    return ps\n",
    "\n",
    "class image_classifier(panoramasdk.base):\n",
    "\n",
    "    def interface(self):\n",
    "        return {\n",
    "            \"parameters\":\n",
    "                (\n",
    "                    (\"model\", \"classifier\", \"Model for classifying images\", \"resnet50_v2\"),\n",
    "                    (\"int\", \"batch_size\", \"Model batch size\", 1),\n",
    "                ),\n",
    "            \"inputs\":\n",
    "                (\n",
    "                    (\"media[]\", \"video_in\", \"Camera input stream\"),\n",
    "                ),\n",
    "            \"outputs\":\n",
    "                (\n",
    "                    (\"media[video_in]\", \"video_out\", \"Camera output stream\"),\n",
    "                )\n",
    "        }\n",
    "\n",
    "\n",
    "    def init(self, parameters, inputs, outputs):\n",
    "        try:\n",
    "            self.frame_num = 0\n",
    "            # Load model from the specified directory.\n",
    "            print(\"loading the model...\")\n",
    "            self.model = panoramasdk.model()\n",
    "            self.model.open(parameters.classifier, 1)\n",
    "            print(\"model loaded\")\n",
    "\n",
    "            # Create input and output arrays.\n",
    "            prob_info = self.model.get_output(0)\n",
    "            \n",
    "            self.prob_array = np.empty(prob_info.get_dims(), dtype=prob_info.get_type())\n",
    "            \n",
    "            self.classes = get_classes()\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Exception: {}\".format(e))\n",
    "            return False\n",
    "\n",
    "    \n",
    "    def topk(self, array, k=5):\n",
    "        enum_vals = [(i, val) for i, val in enumerate(array)]\n",
    "        sorted_vals = sorted(enum_vals, key=lambda tup: tup[1])\n",
    "        top_k = sorted_vals[::-1][:k]\n",
    "        return [tup[0] for tup in top_k]\n",
    "\n",
    "    \n",
    "    def entry(self, inputs, outputs):\n",
    "\n",
    "        for i in range(len(inputs.video_in)):\n",
    "            \n",
    "            stream = inputs.video_in[i]\n",
    "            image = stream.image\n",
    "\n",
    "            x1 = preprocess(image)\n",
    "        \n",
    "            # Do inference on the new frame.\n",
    "            self.model.batch(0, x1)\n",
    "            self.model.flush()\n",
    "            \n",
    "            # Get the results.\n",
    "            resultBatchSet = self.model.get_result()\n",
    "            prob_batch = resultBatchSet.get(0)\n",
    "            prob_batch.get(0, self.prob_array)\n",
    "            \n",
    "            logits = self.prob_array\n",
    "            \n",
    "            topK = 5\n",
    "            probs = softmax(logits)\n",
    "                        \n",
    "            ind = self.topk(probs, k=topK)\n",
    "            \n",
    "            lines = ['Top 5 Classes:']\n",
    "            for j in range(topK):\n",
    "                lines.append('\\n class [%s], with probability %.3f. \\n'% (self.classes[ind[j]], probs[ind[j]]))\n",
    "            message = \"\\n\".join(lines)\n",
    "            \n",
    "    \n",
    "            y0, dy = 0.25, 0.025\n",
    "            for i, line in enumerate(message.split('\\n')):\n",
    "                y = y0 + i*dy\n",
    "                stream.add_label(line, 0.25, y)\n",
    "                        \n",
    "            \n",
    "            self.model.release_result(resultBatchSet)\n",
    "            outputs.video_out[i] = stream\n",
    "        \n",
    "\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    image_classifier().run()\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploying Lambda\n",
    "\n",
    "As mentioned previously, code from above is adapted to run within a notebook environment. You can find actual lambda code in `classification.py` found in the **Lambda** directory. In order to deploy a lambda function from this notebook, you will need the `image-classification.zip` file that contains the following files:\n",
    "- classification.py\n",
    "- imagenet-classes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define boto sessions\n",
    "run the following cell to initialize boto3 to interface with AWS Lambda service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create the role for Lambda Execution\n",
    "running the next cell will create an execution role that will deploy your lambda zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\":[\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"]},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "iam_client = boto3.client(\"iam\")\n",
    "\n",
    "iam_client.create_role(\n",
    "    RoleName=\"ImageClassificationExecutionRole\",\n",
    "    AssumeRolePolicyDocument=json.dumps(role_policy_document),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create the AWS Lambda function\n",
    "Next, the following cell creates the lambda function in your AWS Lambda service and uploads your zip file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -o  ../Lambda/image-classification.zip ../Lambda/imagenet_classes.py ../Lambda/classification.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "with open('../Lambda/image-classification.zip', 'rb') as f:\n",
    "    zipped_code = f.read()\n",
    "\n",
    "role = iam_client.get_role(RoleName='ImageClassificationExecutionRole')\n",
    "response_create_function = lambda_client.create_function(\n",
    "  FunctionName='ImageClassificationLambda',\n",
    "  Runtime='python3.7',\n",
    "  Role=role['Role']['Arn'],\n",
    "  Handler='classification.main()',\n",
    "  Code=dict(ZipFile=zipped_code),\n",
    "  Timeout=120,\n",
    "  MemorySize=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is an ARN?** : Amazon Resource Names (ARNs) uniquely identify AWS resources.\n",
    "\n",
    "The following Python snippet will publish the Lambda Function we created above, and return an ARN with a version. \n",
    "\n",
    "This version arn can be used to go directly to the Panorama console and deploy this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color=None):\n",
    "    \"\"\"\n",
    "    Helper Function for Fomatting Output\n",
    "    \"\"\"\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Publish Lambda\n",
    "Lastly, publish the latest version of you lambda function so that it's available to use in the Panorama Application console. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.publish_version(\n",
    "      FunctionName='ImageClassificationLambda'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the details of the lambda function that was just published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_arn = response[\"FunctionArn\"]\n",
    "function_arn_version = list(response[\"FunctionArn\"].split(\":\"))[-1]\n",
    "lambda_url = (\n",
    "    \"https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/\"\n",
    "    + response[\"FunctionName\"]\n",
    "    + \"/versions/\"\n",
    "    + response[\"Version\"]\n",
    "    + \"?tab=configuration\"\n",
    ")\n",
    "\n",
    "printmd(\"**Function Arn** : **{}**\".format(function_arn), color=\"black\")\n",
    "printmd(\"**Function Arn Version** : **{}**\".format(function_arn_version), color=\"black\")\n",
    "printmd(\"**Lambda Console Link** : **{}**\".format(lambda_url), color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Send Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_model_to_s3(model, bucket = 'aws-panorama-models-bucket'):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.create_bucket(Bucket=bucket)\n",
    "    \n",
    "    key = '../../Models/' + model\n",
    "    \n",
    "    s3.Object(bucket, model).put(Body=open(key, 'rb'))\n",
    "    \n",
    "    bucket_name = bucket\n",
    "    \n",
    "    \n",
    "    location = boto3.client('s3').get_bucket_location(Bucket='aws-panorama-models-bucket')['LocationConstraint']\n",
    "    url = \"s3://{}/{}\".format(bucket_name, model)\n",
    "    \n",
    "    printmd(\"**S3 Path** : **{}**\".format(url), color=\"black\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_model_to_s3(model = 'resnet50_v2.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 : Deploy the Application\n",
    "\n",
    "The Lambda is now created and published. You are now ready to deploy your model and the published lambda function, to the Panorama device\n",
    "\n",
    "The instructions to deploy are linked below\n",
    "\n",
    "[Creating Application Instructions Here](https://docs.aws.amazon.com/panorama/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
