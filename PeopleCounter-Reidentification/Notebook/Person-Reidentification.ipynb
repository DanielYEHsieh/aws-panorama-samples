{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How to create a Person ReIdentification Application using Panorama SDK\n",
    "\n",
    "**Goal of this Notebook** :\n",
    "\n",
    "* Aid an Panorama developer prototype their application before creating the AWS Lambda for Panorama\n",
    "* Using the built in wrapper application that **mimics** the Panorama sdk to get inference from the model\n",
    "\n",
    "**What this Notebook accomplishes?** :\n",
    "* Detect People in a selected video\n",
    "* Using feature extraction to re-identify the person\n",
    "* Use centroids to identify the direction of the movement \n",
    "* Use the direction to determine if the person entered or exited the building and display the entry/exit count on the video frames\n",
    "* Draw bounding boxes around the person after re-identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**CAUTION PLEASE READ BEFORE PROCEEDING** :\n",
    "\n",
    "* The panoramasdk wrapper class used in this demo is not the original Panorama sdk that is on the device image\n",
    "* The wrapper class does not reflect the capabilities of the original Panorama SDK on the device\n",
    "* Its sole purpose is to give a developer a realistic idea of the structure and signature of the sdk on the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video to use\n",
    "video_to_use = \"MOT16-03.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8e93941112dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgluoncv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gluoncv/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0.7.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gluoncv/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mprovides\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpopular\u001b[0m \u001b[0mvision\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatchify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageNet1kAttr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gluoncv/data/transforms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/gluoncv/data/transforms/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumeric_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import clear_output, Markdown, display\n",
    "import json\n",
    "\n",
    "from gluoncv import model_zoo, data, utils\n",
    "import mxnet as mx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n"
   ]
  },
  {
   "source": [
    "## Step 2: Modelling Approach\n",
    "\n",
    "This step walks through using the Panorama SDK (wrapper) model to get inference\n",
    "* Model: ssd_512_resnet50_v1_voc\n",
    "* Dataset: These models are trained on PascalVOC datasets with 20 classes of objects\n",
    "* arXiv: Application of Convolutional Neural Network for Image Classification on Pascal VOC Challenge 2012 dataset\n",
    "* Model Input Size: 512 x 512\n",
    "* Model Output: (1, 100, 1), (1,100,1), (1,100,4)\n",
    "* Isolate people using class index 14 with a confidence higher than 30%\n",
    "* Re-identify the person using torch reid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "** A. Loading the model **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyter_utils'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-19c82ed6a9b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjupyter_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m jupyter_utils.declare_globals({'mxnet_modelzoo_example': True, \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jupyter_utils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.abspath(os.path.join(os.path.dirname(\"panorama_sdk\"), '../..'))\n",
    "sys.path.insert(1, path + '/panorama_sdk')\n",
    "\n",
    "\n",
    "import jupyter_utils\n",
    "\n",
    "jupyter_utils.declare_globals({'mxnet_modelzoo_example': True, \n",
    "                               'custom_model': False, 'task':'object_detection', 'framework':'MXNET'})\n",
    "\n",
    "import panoramasdk\n",
    "\n",
    "print('Loading Model')\n",
    "model = panoramasdk.model()\n",
    "model.open('ssd_512_resnet50_v1_voc', 1)\n",
    "print('Model Loaded')"
   ]
  },
  {
   "source": [
    "** B. Pre processing **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def letterbox_image(img, inp_dim):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    img_w, img_h = img.shape[1], img.shape[0]\n",
    "    w, h = inp_dim\n",
    "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
    "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
    "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
    "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
    "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def preprocess(img, h_size, w_size, letterbox=False):\n",
    "    if letterbox:\n",
    "        resized = letterbox_image(img, (w_size,h_size))\n",
    "    else:\n",
    "        resized = cv2.resize(img, (w_size,h_size), interpolation = cv2.INTER_CUBIC)\n",
    "    mean = [0.485, 0.456, 0.406]  # RGB\n",
    "    std = [0.229, 0.224, 0.225]  # RGB\n",
    "    # converting array of ints to floats\n",
    "    img = resized.astype(np.float32) / 255. \n",
    "    img_a = img[:, :, 0]\n",
    "    img_b = img[:, :, 1]\n",
    "    img_c = img[:, :, 2]\n",
    "    # Extracting single channels from 3 channel image\n",
    "    # The above code could also be replaced with cv2.split(img)\n",
    "    # normalizing per channel data:\n",
    "    img_a = (img_a - mean[0]) / std[0]\n",
    "    img_b = (img_b - mean[1]) / std[1]\n",
    "    img_c = (img_c - mean[2]) / std[2]\n",
    "    # putting the 3 channels back together:\n",
    "    x1 = [[[], [], []]]\n",
    "    x1[0][0] = img_a\n",
    "    x1[0][1] = img_b\n",
    "    x1[0][2] = img_c\n",
    "    x1 = np.asarray(x1)\n",
    "    return x1"
   ]
  },
  {
   "source": [
    "** C. Inference **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Panorama has a unique signature where we have to create empty arrays with the output dimensions before hand\n",
    "\n",
    "# Create input and output arrays.\n",
    "class_info = model.get_output(0)\n",
    "prob_info = model.get_output(1)\n",
    "rect_info = model.get_output(2)\n",
    "\n",
    "class_array = np.empty(class_info.get_dims(), dtype=class_info.get_type())\n",
    "prob_array = np.empty(prob_info.get_dims(), dtype=prob_info.get_type())\n",
    "rect_array = np.empty(rect_info.get_dims(), dtype=rect_info.get_type())\n",
    "\n",
    "person_image = cv2.imread('MOTS20-07.jpg')\n",
    "\n",
    "# Pre Process Frame\n",
    "x1 = preprocess(person_image, 512, 512, True)\n",
    "\n",
    "# Do inference on the new frame.\n",
    "model.batch(0, x1)\n",
    "model.flush()\n",
    "\n",
    "# Get the results.\n",
    "resultBatchSet = model.get_result()\n",
    "\n",
    "class_batch = resultBatchSet.get(0)\n",
    "prob_batch = resultBatchSet.get(1)\n",
    "rect_batch = resultBatchSet.get(2)\n",
    "\n",
    "class_batch.get(0, class_array)\n",
    "prob_batch.get(1, prob_array)\n",
    "rect_batch.get(2, rect_array)\n",
    "\n",
    "class_data = class_array\n",
    "prob_data = prob_array\n",
    "rect_data = rect_array\n",
    "\n",
    "\n",
    "print('Class data shape is ', class_data.shape)\n",
    "print('Confidence data shape is ', prob_data.shape)\n",
    "print('Bounding Boxes data shape is ',rect_data.shape)"
   ]
  },
  {
   "source": [
    "** D. Identify person with 30% or more confidence **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_persons(class_data, prob_data):\n",
    "    # Returns an array the size of class data\n",
    "    # Default false unless the identified object\n",
    "    # is a person with probablity greater than \n",
    "    # the threshold\n",
    "    person_indices = None\n",
    "    number_of_people = 0\n",
    "    if class_data is not None and len(class_data):\n",
    "        person_indices = np.full(len(class_data), False)\n",
    "        for x in range(len(class_data)):\n",
    "            if int(class_data[x]) == 14 and prob_data[x] >= 0.30:\n",
    "                person_indices[x] = True\n",
    "                number_of_people += 1\n",
    "    return person_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'class_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a86ea078891c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperson_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_persons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mperson_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_data' is not defined"
     ]
    }
   ],
   "source": [
    "person_indices = get_persons(class_data[0], prob_data[0])\n",
    "class_data = np.compress(person_indices, class_data[0], axis=0)\n",
    "prob_data = np.compress(person_indices, prob_data[0], axis=0)\n",
    "rect_data = np.compress(person_indices, rect_data[0], axis=0)"
   ]
  },
  {
   "source": [
    "** E. Post processing utilities **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "    # Rescale coords (xyxy) from img1_shape to img0_shape\n",
    "    if ratio_pad is None:  # calculate from img0_shape\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
    "    else:\n",
    "        gain = ratio_pad[0][0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    coords[:, [0, 2]] -= pad[0]  # x padding\n",
    "    coords[:, [1, 3]] -= pad[1]  # y padding\n",
    "    coords[:, :4] /= gain\n",
    "    coords = clip_coords(coords, img0_shape)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def clip_coords(boxes, img_shape):\n",
    "    # Clip bounding xyxy bounding boxes to image shape (height, width)\n",
    "    boxes[:, 0] = np.clip(boxes[:, 0], 0, img_shape[1])  # x1\n",
    "    boxes[:, 1] = np.clip(boxes[:, 1], 0, img_shape[0])  # y1\n",
    "    boxes[:, 2] = np.clip(boxes[:, 2], 0, img_shape[1])  # x2\n",
    "    boxes[:, 3] = np.clip(boxes[:, 3], 0, img_shape[0])  # y2\n",
    "    return boxes\n",
    "\n",
    "def xyxy_to_xywh(boxes_xyxy):\n",
    "    boxes_xywh = boxes_xyxy.copy()\n",
    "    boxes_xywh[:, 0] = (boxes_xyxy[:, 0] + boxes_xyxy[:, 2]) / 2.\n",
    "    boxes_xywh[:, 1] = (boxes_xyxy[:, 1] + boxes_xyxy[:, 3]) / 2.\n",
    "    boxes_xywh[:, 2] = boxes_xyxy[:, 2] - boxes_xyxy[:, 0]\n",
    "    boxes_xywh[:, 3] = boxes_xyxy[:, 3] - boxes_xyxy[:, 1]\n",
    "    for index in range(len(boxes_xywh)):\n",
    "        log(f'X:{boxes_xywh[index][0]} Y: {boxes_xywh[index][1]} W: {boxes_xywh[index][2]} H: {boxes_xywh[index][3]}')\n",
    "    return boxes_xywh"
   ]
  },
  {
   "source": [
    "** F. Load the re-identification model **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_utils\n",
    "\n",
    "jupyter_utils.declare_globals({'mxnet_modelzoo_example': False, \n",
    "                               'custom_model': True, 'task':'PERSON_REID', 'framework':'PYTORCH'})\n",
    "\n",
    "import panoramasdk\n",
    "from importlib import reload  \n",
    "\n",
    "panoramasdk = reload(panoramasdk)\n",
    "\n",
    "print('Loading Model')\n",
    "model = panoramasdk.model()\n",
    "# PLEASE REFER TO Torch-reid.ipynb TO CREATE THIS MODEL\n",
    "model.open('reid_model_v1', 1)\n",
    "print('Model Loaded')"
   ]
  },
  {
   "source": [
    "** G. Re-identification using deep sort **"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path = os.path.abspath(os.path.join(os.path.dirname(\"Lambda\"), './..'))\n",
    "sys.path.insert(1, path + '/Lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort import build_tracker\n",
    "\n",
    "cfg = {}\n",
    "cfg[\"INPUT_SIZE_H\"] = 256\n",
    "cfg[\"INPUT_SIZE_W\"] = 128\n",
    "cfg[\"MAX_DIST\"] = 0.5\n",
    "cfg[\"MIN_CONFIDENCE\"] = 0.3\n",
    "cfg[\"NMS_MAX_OVERLAP\"] = 0.8\n",
    "cfg[\"MAX_IOU_DISTANCE\"] = 0.7\n",
    "cfg[\"MAX_AGE\"] = 70\n",
    "cfg[\"N_INIT\"] = 5\n",
    "cfg[\"NN_BUDGET\"] = 20\n",
    "deepsort = build_tracker(tracking_model, cfg, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python395jvsc74a57bd0ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc",
   "display_name": "Python 3.9.5 64-bit ('python@3.9')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}