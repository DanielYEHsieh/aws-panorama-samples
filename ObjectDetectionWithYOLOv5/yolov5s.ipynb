{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection with YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "----------------\n",
    "This notebook provides a guided tour of deploying a YOLOv5 machine learning model pre-trained with MS COCO dataset using PyTorch to a Panorama appliance. More information about the model including the original model itself can be found in [this repository](https://github.com/ultralytics/yolov5). More specifically, release `v3.0` of the repository was used to build this example.\n",
    "\n",
    "This example includes a model ready to be deployed to a Panorama device (TorchScript export of `yolov5s.pt` model). You can also train your own model using the resources from the aforementioned repository, and if you do that, make sure to export the resulting model to TorchScript (export script is also available in that repository) and pack it into a tarball (`.tar.gz`) before deploying it to the Panorama device.\n",
    "\n",
    "This is an example of inference done on an image captured from a test IP camera\n",
    "\n",
    "![alt Test image inference results](test-result.png \"Test image inference results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & config\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This notebook was tested with Torch v1.6.0, upgrade it in case you are running an older version***\n",
    "\n",
    "Convert the next cell to Code and run it to install the tested version of PyTorch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random as rnd\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import boto3\n",
    "\n",
    "import utils\n",
    "print(f'Using torch {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create your own AWS S3 Bucket making sure its name contains `aws-panorama`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this variable/constant value to be the full name of your bucket, for example \"aws-panorama-example-xyz\"\n",
    "BUCKET = 'aws-panorama-<you-bucket-name-suffix>'  # Bucket name must contain \"aws-panorama\"\n",
    "\n",
    "# TEMP\n",
    "BUCKET = 'aws-panorama-demo'\n",
    "\n",
    "MODELS_S3_PREFIX = 'models'\n",
    "models_s3_url = f's3://{BUCKET}/{MODELS_S3_PREFIX}/'\n",
    "MODEL_SOURCE_URL = 'http://d3m09i4q1na4l7.cloudfront.net/yolov5s-640.tar.gz'\n",
    "\n",
    "MODEL = 'yolov5s'\n",
    "model_file = f'{MODEL}.pth'\n",
    "model_archive = f'{MODEL}-640.tar.gz'\n",
    "\n",
    "LAMBDA = 'yolov5s'\n",
    "\n",
    "LAMBDA_EXECUTION_ROLE_NAME = 'PanoramaYoloLambdaExecutionRole'\n",
    "lambda_file = f'{LAMBDA}_lambda.py'\n",
    "lambda_archive = lambda_file.replace('.py', '.zip')\n",
    "\n",
    "TEST_IMAGE = 'test.png'\n",
    "INPUT_SIZE = 640 \n",
    "THRESHOLD = 0.5\n",
    "CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "           'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "           'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "           'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "           'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "           'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "           'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "           'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', \n",
    "           'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_type = 'GPU'\n",
    "    print(f'Using GPU: {torch.cuda.get_device_properties(0)}')\n",
    "else:\n",
    "    device_type = 'CPU'\n",
    "    print(f'Using {device_type}')\n",
    "\n",
    "device = torch.device('cuda:0' if device_type == 'GPU' else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = boto3.client(\"iam\")\n",
    "lambda_client = boto3.client(\"lambda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the modal locally\n",
    "- Download the provided model archive\n",
    "- Extract the model from the archive\n",
    "- Load the model\n",
    "- Load the test image and prepare it\n",
    "- Put the test image through the model\n",
    "- Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget $MODEL_SOURCE_URL\n",
    "!tar -xvf $model_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(model_file, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image = cv2.cvtColor(cv2.imread(TEST_IMAGE), cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: output of the YOLOv5 model requires further processing (Non Max Suppression) which can be done on GPU using PyTorch but on a Panorama appliance it needs to be executed on CPU (also applies to execution of model's Detector layer logic), adding significant overhead to the overall inference process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = utils.Processor(CLASSES, INPUT_SIZE, keep_ratio=True)\n",
    "\n",
    "tm = time.time()\n",
    "img = torch.from_numpy(processor.preprocess(test_image)).to(device)\n",
    "print(f'Pre-process: {int((time.time() - tm) * 1000)} msec')\n",
    "\n",
    "# Do a warm-up run before timing inference\n",
    "model(img)\n",
    "\n",
    "tm = time.time()\n",
    "results = model(img)\n",
    "print(f'Inference: {int((time.time() - tm) * 1000)} msec')\n",
    "test_results = [r.cpu().numpy() for r in results]\n",
    "\n",
    "tm = time.time()\n",
    "_, result_image = processor.post_process(test_results, test_image.shape, THRESHOLD, test_image.copy())\n",
    "print(f'Post-process: {int((time.time() - tm) * 1000)} msec')\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(result_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the model\n",
    "All we need to do is to upload the model archive to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_model_s3_url = os.path.join(models_s3_url, model_archive)\n",
    "!aws s3 cp $model_archive $jit_model_s3_url\n",
    "!aws s3 ls $jit_model_s3_url --human-readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Application \n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script that will be deployed and executed on the Panorama Appliance as a lambda function. It can found in the same folder as this notebook along with another file `utils.py`, containing some helper scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize $lambda_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and deploy lambda\n",
    "\n",
    "- If the execution of the code in this cell fails then make sure you have the rights to creates roles in AWS IAM\n",
    "- You only need to execute the next cell once. All the subsequent deployments will use the same role "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_execution_role_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\":[\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"]},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "iam_client.create_role(\n",
    "    RoleName=LAMBDA_EXECUTION_ROLE_NAME,\n",
    "    AssumeRolePolicyDocument=json.dumps(lambda_execution_role_policy),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a new function\n",
    "\n",
    "*Use the cell after the next if you want to re-deploy lambda after the initial deployment*\n",
    "\n",
    "You can inspect the created AWS Lambda Function following the link shown after running the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -o $lambda_archive $lambda_file utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client.delete_function(\n",
    "    FunctionName=LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lambda_archive, \"rb\") as f:\n",
    "    zipped_code = f.read()\n",
    "    \n",
    "lambda_execution_role = iam_client.get_role(RoleName=LAMBDA_EXECUTION_ROLE_NAME)\n",
    "\n",
    "lambda_response = lambda_client.create_function(\n",
    "    FunctionName=LAMBDA,\n",
    "    Runtime=\"python3.7\",\n",
    "    Role=lambda_execution_role[\"Role\"][\"Arn\"],\n",
    "    Handler=lambda_file.replace('.py', '.main()'),\n",
    "    Code=dict(ZipFile=zipped_code),\n",
    "    Timeout=120,  \n",
    "    MemorySize=2048,\n",
    "    Publish=True)\n",
    "\n",
    "template = \"https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/{}/versions/{}?tab=configuration\"\n",
    "lambda_url = template.format(lambda_response[\"FunctionName\"], lambda_response[\"Version\"])\n",
    "print(lambda_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [OPTIONAL] Subsequent deployments\n",
    "Convert the next cell to Code and run the following cell if you want to re-deploy the lambda function again, e.g. if you make changes to application code and want to deploy those changes to the Panorama appliance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm $lambda_archive\n",
    "!zip -o $lambda_archive $lambda_file utils.py\n",
    "\n",
    "with open(lambda_archive, \"rb\") as f:\n",
    "    zipped_code = f.read()\n",
    "    \n",
    "lambda_response = lambda_client.update_function_code(\n",
    "    FunctionName=LAMBDA,\n",
    "    ZipFile=zipped_code,\n",
    "    Publish=True)\n",
    "\n",
    "template = \"https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/{}/versions/{}?tab=configuration\"\n",
    "lambda_url = template.format(lambda_response[\"FunctionName\"], lambda_response[\"Version\"])\n",
    "print(lambda_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Application to Panorama appliance \n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing this the only way to deploy the Application to the Panorama device is through the [AWS Panorama Console](https://console.aws.amazon.com/panorama). Instructions for script-based deployment will be added here after alternative means of deployment are available, e.g. via AWS CLI or Python SDK.\n",
    "\n",
    "Few things to remember when deploying the Application to your Panorama appliance in AWS Panorama Console:\n",
    "\n",
    "- when creating a new model (as part of a new Application creation process) in AWS Panorama Console:\n",
    "    - use the model archive uploaded to S3 earlier in this notebook to create a new **External model** (e.g. `s3://< your bucket >/models/yolov5s-640.tar.gz`)\n",
    "    - make sure that the **Model name** you specify matches exactly the model name used in your Application/lambda code (it is stored in the variable/constant named **MODEL** in the current version of the Application/labmda code) *\n",
    "    - select `PyTorch` as *Model framework*\n",
    "    - add input with **Input name** `data` and **Input shape** `1,3,640,640`\n",
    "     \n",
    "- first deployment of the Application takes a bit longer due to initial conversion of the model done by AWS SageMaker Neo behind the scene. Subsequent deployments using the same model will be faster if you only change the Application code (which is usually the case)\n",
    "- to troubleshoot any issues start with looking at the logs in [AWS CloudWatch](https://console.aws.amazon.com/cloudwatch). In the AWS CloudWatch Console, click on **Log Groups** under **Logs** and select a click on a link that has a name of the lambda function corresponding to your Application (something like `/aws/greengrass/Lambda/us-east-1/<your account number>/yolov5s`)\n",
    "\n",
    "***Note:*** *code versions may change making it out of sync with comments in this notebook, always use the latest values from the code when referred to*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just a taster to show you how to run a PyTorch based YOLOv5 model on Panorama appliance. Next logical step would be fine-tuning the pre-trained YOLOv5 model using your own dataset to recognise your own object types. Examples of doing that are available in the repository referencd earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
