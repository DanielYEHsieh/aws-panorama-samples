{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection with YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "----------------\n",
    "This notebook provides a guided tour of deploying a YOLOv5 machine learning model pre-trained with MS COCO dataset using PyTorch to a Panorama appliance. More information about the model including the original model itself can be found in [this repository](https://github.com/ultralytics/yolov5) which is also included as a submodule under `3rdparty/yolov5`.\n",
    "\n",
    "This example shows how to prepare a pre-trained model for deployment to a Panorama device. You can also train your own model using the resources from the aforementioned repository and deploy it to a Panorama appliance following the same steps.\n",
    "\n",
    "This is an example of inference done on an image captured from a test IP camera.\n",
    "\n",
    "![alt Test image inference results](test-result.png \"Test image inference results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & config\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We recommend running this notebook on SageMaker Notebook Instance or SageMaker Studio with `conda_python3` kernel as they come with many libraries used here pre-installed**. \n",
    "\n",
    "If you are not using Amazon SageMaker Notebook Instance or Studio then you need to install some additional libraries, like AWS Python SDK (`boto3`), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import random as rnd\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import boto3\n",
    "\n",
    "import utils\n",
    "print(f'Using torch {torch.__version__}')\n",
    "print(f'Using python {sys.version_info}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create your own AWS S3 Bucket making sure it contains `aws-panorama` in the bucket name***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this variable/constant value to be the full name of your bucket, for example \"aws-panorama-example-xyz\"\n",
    "BUCKET = 'aws-panorama-<you-bucket-name-suffix>'  # Bucket name must contain \"aws-panorama\"\n",
    "\n",
    "MODELS_S3_PREFIX = 'models'\n",
    "\n",
    "MODEL = 'yolov5s'\n",
    "model_file = f'{MODEL}.pt'\n",
    "traced_model_file = f'{MODEL}.pth'\n",
    "traced_model_archive = f'{MODEL}.tar.gz'\n",
    "\n",
    "LAMBDA = 'yolov5s'\n",
    "\n",
    "LAMBDA_EXECUTION_ROLE_NAME = 'PanoramaYoloLambdaExecutionRole'\n",
    "lambda_file = f'{LAMBDA}_lambda.py'\n",
    "lambda_archive = lambda_file.replace('.py', '.zip')\n",
    "\n",
    "TEST_IMAGE = 'test.png'\n",
    "INPUT_SIZE = 640 \n",
    "THRESHOLD = 0.5\n",
    "CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "           'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "           'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "           'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "           'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "           'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "           'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "           'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', \n",
    "           'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    device_type = 'GPU'\n",
    "    print(f'Found GPU: {torch.cuda.get_device_properties(0)}')\n",
    "else:\n",
    "    device_type = 'CPU'\n",
    "\n",
    "# Uncomment next like if you want to force running on a CPU on a device with GPU\n",
    "#device_type = 'CPU'\n",
    "\n",
    "device = torch.device('cuda:0' if device_type == 'GPU' else 'cpu')\n",
    "print(f'Using {device_type}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "lambda_client = boto3.client(\"lambda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "----------------\n",
    "\n",
    "Model preparation steps are completed using the `3rdparty/yolov5` submodule\n",
    "\n",
    "##### Steps to prepare the model\n",
    "1. Download and trace the model\n",
    "    - Install YOLOv5 dependencies\n",
    "    - Run a test inference. This will also download the pre-trained model as save it as `yolov5s.pt` file\n",
    "    - Export the downloaded model to TorchScript format, saved as `yolov5.pth` file\n",
    "2. Test the TorchScript model\n",
    "    - Load the TorchScript model\n",
    "    - Load the test image and prepare it\n",
    "    - Put the test image through the model\n",
    "    - Show results\n",
    "3. Pack and upload the TorchScript model to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install extra dependencies required to execute YOLOv5 scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r 3rdparty/yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_str = 'cpu' if device_type == 'CPU' else '0'\n",
    "out_dir = 'inference_results'\n",
    "yolov4_dir = '3rdparty/yolov5'\n",
    "\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "    \n",
    "!python $yolov4_dir/detect.py --weights $model_file --img $INPUT_SIZE --conf $THRESHOLD --source $TEST_IMAGE \\\n",
    "    --device $device_str --project $out_dir --name \"\"\n",
    "\n",
    "!export PYTHONPATH=$yolov4_dir && python $yolov4_dir/models/export.py --weights $model_file --img-size $INPUT_SIZE\n",
    "!mv yolov5s.torchscript.pt $traced_model_file\n",
    "\n",
    "Image(filename=f'{out_dir}/{TEST_IMAGE}', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the traced model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the traced/exported model and a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.load(traced_model_file, map_location=device)\n",
    "test_image = cv2.cvtColor(cv2.imread(TEST_IMAGE), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: output of the YOLOv5 model requires additional processing (Non Max Suppression) which can be done on GPU using PyTorch but on a Panorama appliance it needs to be executed on a CPU (also applies to execution of model's Detector layer logic), adding significant overhead to the overall inference process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = utils.Processor(CLASSES, INPUT_SIZE, threshold=THRESHOLD, keep_ratio=True)\n",
    "\n",
    "tm = time.time()\n",
    "img = torch.from_numpy(processor.preprocess(test_image)).to(device)\n",
    "print(f'Pre-process: {int((time.time() - tm) * 1000)} msec')\n",
    "\n",
    "# Do warm-up runs before timing inference\n",
    "for i in range(3):\n",
    "    traced_model(img)\n",
    "\n",
    "run_count = 10\n",
    "tm = time.time()\n",
    "for i in range(run_count):\n",
    "    results = traced_model(img)\n",
    "print(f'Average inference time: {int((time.time() - tm) / run_count * 1000)} msec')\n",
    "test_results = [r.cpu().numpy() for r in results]\n",
    "\n",
    "tm = time.time()\n",
    "_, result_image = processor.post_process(test_results, test_image.shape, test_image.copy())\n",
    "print(f'Post-process: {int((time.time() - tm) * 1000)} msec')\n",
    "\n",
    "# Show both the original and marked images\n",
    "_, ax = plt.subplots(2, figsize=(10, 10))\n",
    "ax[0].imshow(test_image)\n",
    "ax[1].imshow(result_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pack and upload the model archive to S3 bucket\n",
    "\n",
    "Take a note of an S3 location of the uploaded model archive, you'll need it during the application creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf $traced_model_archive $traced_model_file\n",
    "\n",
    "traced_model_key = os.path.join(MODELS_S3_PREFIX, traced_model_archive)\n",
    "s3_client.upload_file(traced_model_archive, Bucket=BUCKET, Key=traced_model_key)\n",
    "\n",
    "traced_model_s3_url = os.path.join(f's3://{BUCKET}', traced_model_key)\n",
    "print(f'Uploaded model archive to {traced_model_s3_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can upload the model archive to S3 bucket using AWS Console or running the following AWS CLI command ***if you have AWS CLI installed and configured*** (change the cell to `Code` type before running)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!aws s3 cp $traced_model_archive $traced_model_s3_url\n",
    "!aws s3 ls $traced_model_s3_url --human-readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Application \n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script that will be deployed and executed on the Panorama Appliance as a lambda function. It can found in the same folder as this notebook along with another file `utils.py`, containing some helper scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize $lambda_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and deploy lambda\n",
    "\n",
    "- If the execution of the code in this cell fails then make sure you have the rights to creates roles in AWS IAM\n",
    "- **You only need to execute the next cell once.** All the subsequent deployments will use the same role "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_execution_role_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\":[\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"]},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "iam_client.create_role(\n",
    "    RoleName=LAMBDA_EXECUTION_ROLE_NAME,\n",
    "    AssumeRolePolicyDocument=json.dumps(lambda_execution_role_policy),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a new Lambda Function\n",
    "\n",
    "*Use the cell in the [OPTIONAL] cell below if you want to re-deploy lambda after the initial deployment*\n",
    "\n",
    "You can inspect the created AWS Lambda Function following the link shown after running the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -o $lambda_archive $lambda_file utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following if you already have a function and want to re-create it\n",
    "# lambda_client.delete_function(FunctionName=LAMBDA)\n",
    "\n",
    "with open(lambda_archive, \"rb\") as f:\n",
    "    zipped_code = f.read()\n",
    "    \n",
    "lambda_execution_role = iam_client.get_role(RoleName=LAMBDA_EXECUTION_ROLE_NAME)\n",
    "\n",
    "lambda_response = lambda_client.create_function(\n",
    "    FunctionName=LAMBDA,\n",
    "    Runtime=\"python3.7\",\n",
    "    Role=lambda_execution_role[\"Role\"][\"Arn\"],\n",
    "    Handler=lambda_file.replace('.py', '.main()'),\n",
    "    Code=dict(ZipFile=zipped_code),\n",
    "    Timeout=120,  \n",
    "    MemorySize=2048,\n",
    "    Publish=True)\n",
    "\n",
    "template = \"https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/{}/versions/{}?tab=configuration\"\n",
    "lambda_url = template.format(lambda_response[\"FunctionName\"], lambda_response[\"Version\"])\n",
    "print(lambda_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [OPTIONAL] Subsequent deployments\n",
    "Convert the next cell to Code type and run the following cell if you want to re-deploy the lambda function again, e.g. if you make changes to application code and want to deploy those changes to the Panorama appliance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm $lambda_archive\n",
    "!zip -o $lambda_archive $lambda_file utils.py\n",
    "\n",
    "with open(lambda_archive, \"rb\") as f:\n",
    "    zipped_code = f.read()\n",
    "    \n",
    "lambda_response = lambda_client.update_function_code(\n",
    "    FunctionName=LAMBDA,\n",
    "    ZipFile=zipped_code,\n",
    "    Publish=True)\n",
    "\n",
    "template = \"https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/{}/versions/{}?tab=configuration\"\n",
    "lambda_url = template.format(lambda_response[\"FunctionName\"], lambda_response[\"Version\"])\n",
    "print(lambda_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Application to Panorama appliance \n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing this the only way to deploy the Application to the Panorama device is through the [AWS Panorama Console](https://console.aws.amazon.com/panorama). Instructions for script-based deployment will be added here after alternative means of deployment are available, e.g. via AWS CLI or Python SDK.\n",
    "\n",
    "Few things to remember when deploying the Application to your Panorama appliance in AWS Panorama Console:\n",
    "\n",
    "- when creating a new model (as part of a new Application creation process) in AWS Panorama Console:\n",
    "    - use the model archive uploaded to S3 earlier in this notebook to create a new **External model** (e.g. `s3://< your bucket >/models/yolov5s.tar.gz`)\n",
    "    - make sure that the **Model name** you specify matches exactly the model name used in your Application/lambda code (it is stored in the variable/constant named **MODEL** in the current version of the Application/labmda code) *\n",
    "    - select `PyTorch` as *Model framework*\n",
    "    - add input with **Input name** `data` and **Input shape** `1,3,640,640`\n",
    "     \n",
    "- first deployment of the Application takes a bit longer due to initial conversion of the model done by AWS SageMaker Neo behind the scene. Subsequent deployments using the same model will be faster if you only change the Application code (which is usually the case)\n",
    "- to troubleshoot any issues start with looking at the logs in [AWS CloudWatch](https://console.aws.amazon.com/cloudwatch). In the AWS CloudWatch Console, click on **Log Groups** under **Logs** and select a click on a link that has a name of the lambda function corresponding to your Application (something like `/aws/greengrass/Lambda/us-east-1/<your account number>/yolov5s`)\n",
    "\n",
    "***Note:*** *code versions may change making it out of sync with comments in this notebook, always use the latest values from the code when referred to*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just a taster to show you how to run a PyTorch based YOLOv5 model on Panorama appliance. Next logical step would be fine-tuning the pre-trained YOLOv5 model using your own dataset to recognise your own object types. Examples of doing that are available in the `3rdparty/yolov5` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
