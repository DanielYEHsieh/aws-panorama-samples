{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How to create a simple People Counter Application using Panorama SDK\n",
    "\n",
    "**Goal of this Notebook** :\n",
    "\n",
    "* Aid an Panorama developer prototype their application before creating the AWS Lambda for Panorama\n",
    "* Using the built in wrapper application that **mimics** the Panorama sdk to get inference from the model\n",
    "* Create and Deploy the AWS Lambda for Panorama from this notebook\n",
    "\n",
    "**What this Notebook accomplishes?** :\n",
    "* Detect People in a selected video\n",
    "* Draw bounding boxes around the people\n",
    "* Count the number of people detected\n",
    "* Display the count on the video frames\n",
    "\n",
    "\n",
    "**Useful Resources to aid your development**:\n",
    "* [AWS Panorama Documentation](https://docs.aws.amazon.com/panorama/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**CAUTION PLEASE READ BEFORE PROCEEDING** :\n",
    "\n",
    "* The panoramasdk wrapper class used in this demo is not the original Panorama sdk that is on the device image\n",
    "* The wrapper class does not reflect the capabilities of the original Panorama SDK on the device\n",
    "* Its sole purpose is to give a developer a realistic idea of the structure and signature of the sdk on the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre -Requisites**:\n",
    "* Sagemaker Instance created with the right role (Policies needed IOT, Lambda and S3, IAM Full Access) \n",
    "\n",
    "\n",
    "\n",
    "**Frames to Process**:\n",
    "\n",
    "* By default, we only process 10 frames from the video. If you want to increase this, please change this value in /panorama_sdk/panoramasdk.py and change frames_to_process = 10 to a value of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_use = \"TownCentreXVID.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import Non Panorama Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import clear_output, Markdown, display\n",
    "import json\n",
    "\n",
    "from gluoncv import model_zoo, data, utils\n",
    "import mxnet as mx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Modelling Approach\n",
    "\n",
    "This step walks through using the Panorama SDK (wrapper) model to get inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Model** : ssd_512_resnet50_v1_voc\n",
    "* **Dataset** : These models are trained on [PascalVOC](http://host.robots.ox.ac.uk/pascal/VOC/) datasets with 20 classes of objects  \n",
    "* **arXiv** :[Application of Convolutional Neural Network for Image\n",
    "Classification on Pascal VOC Challenge 2012 dataset](https://arxiv.org/pdf/1607.03785.pdf)  \n",
    "* **Model Input Size** : 512 x 512  \n",
    "* **Model Output** : (1, 100, 1), (1,100,1), (1,100,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **A. Loading the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.abspath(os.path.join(os.path.dirname(\"panorama_sdk\"), '../..'))\n",
    "sys.path.insert(1, path + '/panorama_sdk')\n",
    "\n",
    "import panoramasdk\n",
    "import jupyter_utils\n",
    "\n",
    "print('Loading Model')\n",
    "model = panoramasdk.model()\n",
    "model.open('ssd_512_resnet50_v1_voc', 1)\n",
    "print('Model Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **B. Pre Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, size):\n",
    "\n",
    "    resized = cv2.resize(img, (size, size))\n",
    "    mean = [0.485, 0.456, 0.406]  # RGB\n",
    "    std = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "    img = resized.astype(np.float32) / 255.  # converting array of ints to floats\n",
    "    img_a = img[:, :, 0]\n",
    "    img_b = img[:, :, 1]\n",
    "    img_c = img[:, :, 2]\n",
    "\n",
    "    # Extracting single channels from 3 channel image\n",
    "    # The above code could also be replaced with cv2.split(img) << which will return 3 numpy arrays (using opencv)\n",
    "    # normalizing per channel data:\n",
    "    img_a = (img_a - mean[0]) / std[0]\n",
    "    img_b = (img_b - mean[1]) / std[1]\n",
    "    img_c = (img_c - mean[2]) / std[2]\n",
    "\n",
    "    # putting the 3 channels back together:\n",
    "    x1 = [[[], [], []]]\n",
    "    x1[0][0] = img_a\n",
    "    x1[0][1] = img_b\n",
    "    x1[0][2] = img_c\n",
    "    x1 = np.asarray(x1)\n",
    "\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **C. Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Panorama has a unique signature where we have to create empty arrays with the output dimensions before hand\n",
    "\n",
    "# Create input and output arrays.\n",
    "class_info = model.get_output(0)\n",
    "prob_info = model.get_output(1)\n",
    "rect_info = model.get_output(2)\n",
    "\n",
    "class_array = np.empty(class_info.get_dims(), dtype=class_info.get_type())\n",
    "prob_array = np.empty(prob_info.get_dims(), dtype=prob_info.get_type())\n",
    "rect_array = np.empty(rect_info.get_dims(), dtype=rect_info.get_type())\n",
    "\n",
    "person_image = cv2.imread('street_empty.jpg')\n",
    "\n",
    "# Pre Process Frame\n",
    "x1 = preprocess(person_image, 512)\n",
    "\n",
    "# Do inference on the new frame.\n",
    "model.batch(0, x1)\n",
    "model.flush()\n",
    "\n",
    "# Get the results.\n",
    "resultBatchSet = model.get_result()\n",
    "\n",
    "class_batch = resultBatchSet.get(0)\n",
    "prob_batch = resultBatchSet.get(1)\n",
    "rect_batch = resultBatchSet.get(2)\n",
    "\n",
    "class_batch.get(0, class_array)\n",
    "prob_batch.get(1, prob_array)\n",
    "rect_batch.get(2, rect_array)\n",
    "\n",
    "class_data = class_array\n",
    "prob_data = prob_array\n",
    "rect_data = rect_array\n",
    "\n",
    "\n",
    "print('Class data shape is ', class_data.shape)\n",
    "print('Confidence data shape is ', prob_data.shape)\n",
    "print('Bounding Boxes data shape is ',rect_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 : Understanding and creating the Structure of the Application\n",
    "\n",
    "The Panorama Lambda function has the following structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lambda skeleton\n",
    "\n",
    "\n",
    "class people_counter(object):\n",
    "    def interface(self):\n",
    "        # defines the parameters that interface with other services from Panorama\n",
    "        return\n",
    "\n",
    "    def init(self, parameters, inputs, outputs):\n",
    "        # defines the attributes such as arrays and model objects that will be used in the application\n",
    "        return\n",
    "\n",
    "    def entry(self, inputs, outputs):\n",
    "        # defines the application logic responsible for predicting using the inputs and handles what to do\n",
    "        # with the outputs\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 : Let us use the panoramasdk wrapper function to simulate a real Panorama device lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_utils.change_video_source(video_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panoramasdk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "# [AWS Panorama Documentation](https://docs.aws.amazon.com/panorama/)\n",
    "\n",
    "\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "\n",
    "class people_counter(panoramasdk.base):\n",
    "    \n",
    "    def interface(self):\n",
    "        return {\n",
    "                \"parameters\":\n",
    "                (\n",
    "                    (\"float\", \"threshold\", \"Detection threshold\", 0.10),\n",
    "                    (\"model\", \"person_detection\", \"Model for detecting persons\", \"ssd_512_resnet50_v1_voc\"), \n",
    "                    (\"int\", \"batch_size\", \"Model batch size\", 1),\n",
    "                    (\"float\", \"person_index\", \"person index based on dataset used\", 14),\n",
    "                ),\n",
    "                \"inputs\":\n",
    "                (\n",
    "                    (\"media[]\", \"video_in\", \"Camera input stream\"),\n",
    "                ),\n",
    "                \"outputs\":\n",
    "                (\n",
    "                    (\"media[video_in]\", \"video_out\", \"Camera output stream\"),\n",
    "                    \n",
    "                ) \n",
    "            }\n",
    "    \n",
    "    \n",
    "    \"\"\"init() function is called once by the Lambda runtime.  It gives Lambda a chance to perform \n",
    "    any necessary initialization before entering the main loop.\"\"\"\n",
    "        \n",
    "    def init(self, parameters, inputs, outputs):  \n",
    "        try:  \n",
    "            \"\"\"panoramasdk.model : Creates an Panorama.model object.\"\"\"\n",
    "            \n",
    "            print('Loading Model')\n",
    "            self.model = panoramasdk.model()\n",
    "            self.model.open(parameters.person_detection, 1)\n",
    "            print('Model Loaded')\n",
    "            \n",
    "            # Detection probability threshold.\n",
    "            self.threshold = parameters.threshold\n",
    "            # Frame Number Initialization\n",
    "            self.frame_num = 0\n",
    "            # Number of People\n",
    "            self.number_people = 0\n",
    "            # Bounding Box Colors\n",
    "            self.colours = np.random.rand(32, 3)\n",
    "            # Person Index for Model from parameters\n",
    "            self.person_index = parameters.person_index\n",
    "            # Set threshold for model from parameters \n",
    "            self.threshold = parameters.threshold\n",
    "            \n",
    "            \"\"\"model.get_output : Return a model.output_array object that represents output of the model.\"\"\"\n",
    "            \n",
    "            class_info = self.model.get_output(0)\n",
    "            prob_info = self.model.get_output(1)\n",
    "            rect_info = self.model.get_output(2)\n",
    "\n",
    "            self.class_array = np.empty(class_info.get_dims(), dtype=class_info.get_type())\n",
    "            self.prob_array = np.empty(prob_info.get_dims(), dtype=prob_info.get_type())\n",
    "            self.rect_array = np.empty(rect_info.get_dims(), dtype=rect_info.get_type())\n",
    "\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Exception: {}\".format(e))\n",
    "            return False\n",
    "\n",
    "    def preprocess(self, img, size):\n",
    "        \n",
    "        resized = cv2.resize(img, (size, size))\n",
    "        mean = [0.485, 0.456, 0.406]  # RGB\n",
    "        std = [0.229, 0.224, 0.225]  # RGB\n",
    "        \n",
    "        img = resized.astype(np.float32) / 255.  # converting array of ints to floats\n",
    "        img_a = img[:, :, 0]\n",
    "        img_b = img[:, :, 1]\n",
    "        img_c = img[:, :, 2]\n",
    "        \n",
    "        # Extracting single channels from 3 channel image\n",
    "        # The above code could also be replaced with cv2.split(img) << which will return 3 numpy arrays (using opencv)\n",
    "        # normalizing per channel data:\n",
    "        img_a = (img_a - mean[0]) / std[0]\n",
    "        img_b = (img_b - mean[1]) / std[1]\n",
    "        img_c = (img_c - mean[2]) / std[2]\n",
    "        \n",
    "        # putting the 3 channels back together:\n",
    "        x1 = [[[], [], []]]\n",
    "        x1[0][0] = img_a\n",
    "        x1[0][1] = img_b\n",
    "        x1[0][2] = img_c\n",
    "        x1 = np.asarray(x1)\n",
    "        \n",
    "        return x1\n",
    "    \n",
    "    def get_number_persons(self, class_data, prob_data):\n",
    "        \n",
    "        # get indices of people detections in class data\n",
    "        person_indices = [i for i in range(len(class_data)) if int(class_data[i]) == self.person_index]\n",
    "        # use these indices to filter out anything that is less than 95% threshold from prob_data\n",
    "        prob_person_indices = [i for i in person_indices if prob_data[i] >= self.threshold]\n",
    "        return prob_person_indices\n",
    "    \n",
    "    \n",
    "    \"\"\"entry() function is called by the Lambda runtime from the main loop whenever there’s input data available for processing. \n",
    "    The job of the  entry() function is to process the input data as fast as possible, generate and assign outputs as required by a particular algorithm, \n",
    "    and return back to the main loop. \"\"\"\n",
    "    \n",
    "    def entry(self, inputs, outputs):\n",
    "        self.frame_num += 1\n",
    "        \n",
    "        for i in range(len(inputs.video_in)):\n",
    "            \n",
    "            \n",
    "            stream = inputs.video_in[i]\n",
    "            \n",
    "            \"\"\"numpy.array that contains the latest stream image data.\"\"\"\n",
    "            \n",
    "            person_image = stream.image\n",
    "            w, h, c = person_image.shape\n",
    "\n",
    "            # Pre Process Frame\n",
    "            x1 = self.preprocess(person_image, 512)\n",
    "                                    \n",
    "            # Do inference on the new frame.\n",
    "            \n",
    "            \"\"\"\n",
    "            model.batch \n",
    "            \n",
    "            *Returns: *None*.*\n",
    "            *Parameter:*\n",
    "\n",
    "            * *input_idx (int):* One model might provide multiple inputs. This index represents the specific input model.\n",
    "            * *input_data_array (numpy.array):* The actual array data that you want to send for inference.\n",
    "\n",
    "            \"\"\"\n",
    "            \n",
    "            self.model.batch(0, x1)\n",
    "            \n",
    "            \"\"\"model.flush : An unblocking call that sends all input data provided through .batch(input_idx, input_data_array) to make inference.\"\"\"\n",
    "            \n",
    "            self.model.flush()\n",
    "            \n",
    "            \"\"\"model.get_result : Gets inference results.\"\"\"\n",
    "            \n",
    "            resultBatchSet = self.model.get_result()\n",
    "            \n",
    "            \"\"\".get : Gets data from specific index of a batched output array. \"\"\"\n",
    "            \n",
    "            class_batch = resultBatchSet.get(0)\n",
    "            prob_batch = resultBatchSet.get(1)\n",
    "            rect_batch = resultBatchSet.get(2)\n",
    "\n",
    "            class_batch.get(0, self.class_array)\n",
    "            prob_batch.get(1, self.prob_array)\n",
    "            rect_batch.get(2, self.rect_array)\n",
    "\n",
    "            class_data = self.class_array[0]\n",
    "            prob_data = self.prob_array[0]\n",
    "            rect_data = self.rect_array[0]\n",
    "            \n",
    "            \n",
    "            # Get Indices of classes that correspond to People\n",
    "            person_indices = self.get_number_persons(class_data, prob_data)\n",
    "            \n",
    "            try:\n",
    "                self.number_people = len(person_indices)\n",
    "            except:\n",
    "                self.number_people = 0\n",
    "            \n",
    "            # Visualize with Opencv or stream.(media) \n",
    "            \n",
    "            if self.number_people > 0:\n",
    "                for index in person_indices:\n",
    "                    \n",
    "                    left = np.clip(rect_data[index][0] / np.float(HEIGHT), 0, 1)\n",
    "                    top = np.clip(rect_data[index][1] / np.float(WIDTH), 0, 1)\n",
    "                    right = np.clip(rect_data[index][2] / np.float(HEIGHT), 0, 1)\n",
    "                    bottom = np.clip(rect_data[index][3] / np.float(WIDTH), 0, 1)\n",
    "                    \n",
    "                    \n",
    "                    \"\"\"Add_Rect, Add_label : Adds text label aand nnotations to the data stream.\"\"\"\n",
    "                    \n",
    "                    stream.add_rect(left, top, right, bottom)\n",
    "                    stream.add_label(str(prob_data[index][0]), right, bottom) \n",
    "                    \n",
    "                    \n",
    "     \n",
    "            stream.add_label('Number of People : {}'.format(self.number_people), 0.1, 0.1)\n",
    "        \n",
    "            \"\"\".release_result : Releases the inference result reference and frees up the data slot for reuse. \n",
    "            The model inference loop removes the inference result data that was buffered.\"\"\"\n",
    "            \n",
    "            self.model.release_result(resultBatchSet)\n",
    "            \n",
    "            outputs.video_out[i] = stream\n",
    "            \n",
    "\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"run() member function is implemented in the Lambda base class. It performs Lambda initialization and enters the main loop.\"\"\"\n",
    "    \n",
    "    people_counter().run()\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 : Upload Lambda and Create Lambda Function\n",
    "\n",
    "* A lambda is already provided and ready for use in the lambda folder (zip file)\n",
    "* Use this code snippet to upload and publish it to Lambda Service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python snippet uses boto3 to create an IAM role named LambdaBasicExecution with basic \n",
    "lambda execution permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\":[\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"]},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "iam_client = boto3.client(\"iam\")\n",
    "\n",
    "iam_client.create_role(\n",
    "    RoleName=\"PeopleCounterExecutionRole\",\n",
    "    AssumeRolePolicyDocument=json.dumps(role_policy_document),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Python snippet will use the resources above to create a new AWS Lambda function called PeopleCounterLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -o  ../Lambda/people_counter.zip  ../Lambda/people_counter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client = boto3.client(\"lambda\")\n",
    "\n",
    "with open(\n",
    "    \"../Lambda/people_counter.zip\", \"rb\"\n",
    ") as f:\n",
    "    zipped_code = f.read()\n",
    "\n",
    "role = iam_client.get_role(RoleName=\"PeopleCounterExecutionRole\")\n",
    "\n",
    "response_create_function = lambda_client.create_function(\n",
    "    FunctionName=\"PeopleCounterLambda\",\n",
    "    Runtime=\"python3.7\",\n",
    "    Role=role[\"Role\"][\"Arn\"],\n",
    "    Handler=\"people_counter.main\",\n",
    "    Code=dict(ZipFile=zipped_code),\n",
    "    Timeout=120,\n",
    "    MemorySize=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is an ARN?** : Amazon Resource Names (ARNs) uniquely identify AWS resources.\n",
    "\n",
    "The following Python snippet will publish the Lambda Function we created above, and return an ARN with a version. \n",
    "\n",
    "This version arn can be used to go directly to the Panorama console and deploy this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color=None):\n",
    "    \"\"\"\n",
    "    Helper Function for Fomatting Output\n",
    "    \"\"\"\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.publish_version(FunctionName=\"PeopleCounterLambda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the details of the lambda function that was just published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_arn = response[\"FunctionArn\"]\n",
    "function_arn_version = list(response[\"FunctionArn\"].split(\":\"))[-1]\n",
    "lambda_url = (\n",
    "    \"https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/\"\n",
    "    + response[\"FunctionName\"]\n",
    "    + \"/versions/\"\n",
    "    + response[\"Version\"]\n",
    "    + \"?tab=configuration\"\n",
    ")\n",
    "\n",
    "printmd(\"**Function Arn** : **{}**\".format(function_arn), color=\"black\")\n",
    "printmd(\"**Function Arn Version** : **{}**\".format(function_arn_version), color=\"black\")\n",
    "printmd(\"**Lambda Console Link** : **{}**\".format(lambda_url), color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : Upload Model to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_model_to_s3(model, bucket = 'aws-panorama-models-bucket'):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.create_bucket(Bucket=bucket)\n",
    "    \n",
    "    key = '../../Models/' + model\n",
    "    \n",
    "    s3.Object(bucket, model).put(Body=open(key, 'rb'))\n",
    "    \n",
    "    bucket_name = bucket\n",
    "    \n",
    "    \n",
    "    location = boto3.client('s3').get_bucket_location(Bucket='aws-panorama-models-bucket')['LocationConstraint']\n",
    "    url = \"s3://{}/{}\".format(bucket_name, model)\n",
    "    \n",
    "    printmd(\"**S3 Path** : **{}**\".format(url), color=\"black\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_model_to_s3(model = 'ssd_512_resnet50_v1_voc.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 : Deploy the Application\n",
    "\n",
    "The Lambda is now created and published. You are now ready to deploy your model and the published lambda function, to the Panorama device\n",
    "\n",
    "The instructions to deploy are linked below\n",
    "\n",
    "[Creating Application Instructions Here](https://docs.aws.amazon.com/panorama/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
